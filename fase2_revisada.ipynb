{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f75e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base de datos 'musica_db' creada o verificada en el servidor.\n",
      "‚úÖ Conexi√≥n establecida a la base de datos MySQL: musica_db\n",
      "\n",
      "--- ¬°LISTO PARA LA CARGA DE DATOS Y MODELADO! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, BigInteger, Text, VARCHAR\n",
    "from sqlalchemy.sql import text\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar las credenciales y definir el motor de conexi√≥n\n",
    "load_dotenv('2.env')\n",
    "\n",
    "CSV_FILENAME = 'reggaeton_data_2010_2024.csv' # Esto se usar√° solo si es necesario, pero la Celda 2 lo anula.\n",
    "DB_USER = os.getenv(\"MYSQL_USER\")\n",
    "DB_PASSWORD = os.getenv(\"MYSQL_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"MYSQL_HOST\")\n",
    "# Usaremos 'musica_db' directamente\n",
    "DB_DATABASE = \"musica_db\"\n",
    "\n",
    "engine = None # Inicializamos la variable\n",
    "\n",
    "try:\n",
    "    # --- PASO 1: CONECTARSE AL SERVIDOR Y CREAR LA BASE DE DATOS ---\n",
    "   \n",
    "    # 1.1 Conexi√≥n sin especificar la base de datos (Database=None)\n",
    "    conn_no_db = mysql.connector.connect(\n",
    "        host=DB_HOST,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    cursor = conn_no_db.cursor()\n",
    "   \n",
    "    # 1.2 Crear la base de datos si no existe\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {DB_DATABASE}\")\n",
    "    cursor.close()\n",
    "    conn_no_db.close()\n",
    "   \n",
    "    print(f\"‚úÖ Base de datos '{DB_DATABASE}' creada o verificada en el servidor.\")\n",
    "   \n",
    "   \n",
    "    # --- PASO 2: CREAR EL ENGINE FINAL CON LA BASE DE DATOS ESPECIFICADA ---\n",
    "   \n",
    "    mysql_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_DATABASE}\"\n",
    "    engine = create_engine(mysql_url)\n",
    "   \n",
    "    print(f\"‚úÖ Conexi√≥n establecida a la base de datos MySQL: {DB_DATABASE}\")\n",
    "\n",
    "    print(\"\\n--- ¬°LISTO PARA LA CARGA DE DATOS Y MODELADO! ---\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ùå ERROR: Aseg√∫rate de que instalaste 'mysql-connector-python' o 'mysqlclient'.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR CR√çTICO DE CONEXI√ìN: Verifica que tu servidor MySQL est√© encendido y tus credenciales en '2.env' sean correctas. Detalle: {e}\")\n",
    "    engine = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76beba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO CARGA Y CONCATENACI√ìN DE G√âNEROS ---\n",
      "   -> Cargado reggaeton_data_2010_2024.csv (Reggaeton) con 500 filas.\n",
      "   -> Cargado latin_data_2010_2024.csv (Pop Latino) con 500 filas.\n",
      "   -> Cargado funk_data_2010_2024.csv (Funk) con 500 filas.\n",
      "   -> Cargado indie_data_2010_2024.csv (Rock Indie) con 500 filas.\n",
      "   -> Cargado data_jazz_final2.csv (Jazz) con 500 filas.\n",
      "\n",
      "‚úÖ Proceso completado. Total √∫nico: 2468 canciones.\n",
      "‚úÖ Datos de √Ålbumes y Last.fm reparados para MySQL.\n"
     ]
    }
   ],
   "source": [
    "# --- FASE 2, CELDA 2: CONSOLIDACI√ìN, LIMPIEZA MAESTRA Y MAPEO DE G√âNEROS ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Lista de archivos y sus g√©neros correspondientes\n",
    "file_info = [\n",
    "    {'name': 'reggaeton_data_2010_2024.csv', 'genre': 'Reggaeton'},\n",
    "    {'name': 'latin_data_2010_2024.csv', 'genre': 'Pop Latino'},\n",
    "    {'name': 'funk_data_2010_2024.csv', 'genre': 'Funk'},\n",
    "    {'name': 'indie_data_2010_2024.csv', 'genre': 'Rock Indie'},\n",
    "    {'name': 'data_jazz_final2.csv', 'genre': 'Jazz'}\n",
    "]\n",
    "\n",
    "all_dataframes = []\n",
    "print(\"--- INICIANDO CARGA Y CONCATENACI√ìN DE G√âNEROS ---\")\n",
    "\n",
    "for info in file_info:\n",
    "    filename = info['name']\n",
    "    genre = info['genre']\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Genero'] = genre\n",
    "        \n",
    "        # Estandarizaci√≥n de nombres de columnas comunes antes de unir\n",
    "        if 'A√±o de lanzamiento' in df.columns:\n",
    "            df.rename(columns={'A√±o de lanzamiento': 'A√±o_lanzamiento'}, inplace=True)\n",
    "            \n",
    "        all_dataframes.append(df)\n",
    "        print(f\"   -> Cargado {filename} ({genre}) con {len(df)} filas.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ‚ùå ERROR: Archivo NO encontrado: {filename}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error al leer {filename}: {e}\")\n",
    "\n",
    "# Uni√≥n de todos los g√©neros\n",
    "df_consolidado = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# 2. Deduplicaci√≥n por ID de Spotify\n",
    "df_consolidado.drop_duplicates(subset=['ID_Spotify'], keep='first', inplace=True)\n",
    "\n",
    "# --- üõ†Ô∏è BLOQUE DE REPARACI√ìN DE √ÅLBUMES (SOLUCI√ìN A LOS NULL EN SQL) ---\n",
    "\n",
    "# Aseguramos que existan las columnas de √°lbum\n",
    "cols_album = ['Nombre_Album', 'A√±o_Lanzamiento_Album', 'ID_Album']\n",
    "for col in cols_album:\n",
    "    if col not in df_consolidado.columns:\n",
    "        df_consolidado[col] = np.nan\n",
    "\n",
    "# Relleno de Nombre_Album: si es nulo, usamos el nombre de la canci√≥n\n",
    "df_consolidado['Nombre_Album'] = df_consolidado['Nombre_Album'].fillna(df_consolidado['Nombre'])\n",
    "\n",
    "# Relleno de A√±o_Lanzamiento_Album: si es nulo, usamos el a√±o de la canci√≥n\n",
    "if 'A√±o_lanzamiento' in df_consolidado.columns:\n",
    "    df_consolidado['A√±o_Lanzamiento_Album'] = df_consolidado['A√±o_Lanzamiento_Album'].fillna(df_consolidado['A√±o_lanzamiento'])\n",
    "\n",
    "# Limpieza final para evitar cualquier NULL restante\n",
    "df_consolidado['Nombre_Album'] = df_consolidado['Nombre_Album'].fillna('√Ålbum Desconocido')\n",
    "df_consolidado['ID_Album'] = df_consolidado['ID_Album'].fillna('Sencillo_ID')\n",
    "df_consolidado['A√±o_Lanzamiento_Album'] = df_consolidado['A√±o_Lanzamiento_Album'].fillna(2024).astype(int)\n",
    "\n",
    "# 3. LIMPIEZA DE LAST.FM (Listeners y Playcount)\n",
    "for col in ['Playcount_LastFM', 'Listeners_LastFM']:\n",
    "    if col in df_consolidado.columns:\n",
    "        df_consolidado[col] = df_consolidado[col].fillna(0).astype('Int64')\n",
    "    else:\n",
    "        df_consolidado[col] = 0\n",
    "\n",
    "if 'Biografia_Resumen' in df_consolidado.columns:\n",
    "    df_consolidado['Biografia_Resumen'] = df_consolidado['Biografia_Resumen'].fillna('Sin biograf√≠a disponible.')\n",
    "\n",
    "# --- MAPEO DE G√âNEROS ---\n",
    "\n",
    "df_generos_map = df_consolidado[['Genero']].drop_duplicates().reset_index(drop=True)\n",
    "df_generos_map['genero_id'] = df_generos_map.index + 1\n",
    "df_generos_db = df_generos_map[['genero_id', 'Genero']].rename(columns={'Genero': 'nombre_genero'})\n",
    "\n",
    "df_consolidado = pd.merge(\n",
    "    df_consolidado,\n",
    "    df_generos_map[['Genero', 'genero_id']],\n",
    "    on='Genero',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Proceso completado. Total √∫nico: {len(df_consolidado)} canciones.\")\n",
    "print(\"‚úÖ Datos de √Ålbumes y Last.fm reparados para MySQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb20b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO INSERCI√ìN DE DATOS CONSOLIDADOS EN MYSQL ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_21972\\1988075318.py:23: UserWarning: The provided table name 'GENEROS' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_generos_db.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Insertados 5 g√©neros √∫nicos en la tabla GENEROS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_21972\\1988075318.py:58: UserWarning: The provided table name 'ARTISTAS' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_artistas.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Insertados 1250 artistas √∫nicos en la tabla ARTISTAS (con m√©tricas Last.fm).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_21972\\1988075318.py:89: UserWarning: The provided table name 'ALBUMES' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_albumes.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Insertados 1489 √°lbumes √∫nicos en la tabla ALBUMES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_21972\\1988075318.py:129: UserWarning: The provided table name 'CANCIONES' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_canciones.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Insertadas 2468 canciones √∫nicas en la tabla CANCIONES (con Popularidad).\n",
      "\n",
      "--- FASE 2 (MODELADO) COMPLETADA. Datos normalizados insertados en MySQL. ---\n",
      "\n",
      "--- VERIFICACI√ìN DE G√âNEROS Y POPULARIDAD EN LA BASE DE DATOS ---\n",
      "  nombre_genero  Total_Canciones  Avg_Popularidad\n",
      "0          Jazz              496            33.36\n",
      "1          Funk              499            18.33\n",
      "2    Pop Latino              490            40.54\n",
      "3    Rock Indie              483            38.14\n",
      "4     Reggaeton              500            45.30\n"
     ]
    }
   ],
   "source": [
    "# --- CELDA 3: INSERCI√ìN DE DATOS CON NORMALIZACI√ìN EN MYSQL (CORREGIDA: SOLO A√ëADIDA POPULARIDAD) ---\n",
    "if 'engine' not in locals() or engine is None:\n",
    "    print(\"‚ùå ERROR: El motor de conexi√≥n a MySQL no se cre√≥ correctamente.\")\n",
    "elif 'df_consolidado' not in locals():\n",
    "    print(\"‚ùå ERROR: El DataFrame consolidado no se encontr√≥. ¬°Ejecuta la Celda 2 (Consolidaci√≥n) primero!\")\n",
    "else:\n",
    "    print(\"--- INICIANDO INSERCI√ìN DE DATOS CONSOLIDADOS EN MYSQL ---\")\n",
    "\n",
    "    # Limpieza previa de tablas para evitar problemas con to_sql/replace y claves\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS CANCIONES\"))\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS ALBUMES\"))\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS ARTISTAS\"))\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS GENEROS\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # 0. Crear e insertar la tabla GENEROS\n",
    "    df_generos_db.to_sql(\n",
    "        'GENEROS',\n",
    "        engine,\n",
    "        if_exists='fail'\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'genero_id': Integer,\n",
    "            'nombre_genero': VARCHAR(50)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(\n",
    "            text(\n",
    "                \"ALTER TABLE GENEROS \"\n",
    "                \"MODIFY genero_id INT NOT NULL AUTO_INCREMENT, \"\n",
    "                \"ADD PRIMARY KEY (genero_id)\"\n",
    "            )\n",
    "        )\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"‚úÖ Insertados {len(df_generos_db)} g√©neros √∫nicos en la tabla GENEROS.\")\n",
    "\n",
    "    # 1. Preparar e insertar la tabla ARTISTAS (con datos de Last.fm)\n",
    "    df_artistas = df_consolidado[\n",
    "        [\n",
    "            'Artista',\n",
    "            'Playcount_LastFM',\n",
    "            'Listeners_LastFM',\n",
    "            'Biografia_Resumen'\n",
    "        ]\n",
    "    ].drop_duplicates(subset=['Artista']).dropna(subset=['Artista'])\n",
    "\n",
    "    df_artistas = df_artistas.replace({np.nan: None})\n",
    "\n",
    "    df_artistas.to_sql(\n",
    "        'ARTISTAS',\n",
    "        engine,\n",
    "        if_exists='fail',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'Artista': VARCHAR(255),\n",
    "            'Playcount_LastFM': BigInteger,\n",
    "            'Listeners_LastFM': BigInteger,\n",
    "            'Biografia_Resumen': Text\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"ALTER TABLE ARTISTAS ADD PRIMARY KEY (Artista)\"))\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"‚úÖ Insertados {len(df_artistas)} artistas √∫nicos en la tabla ARTISTAS (con m√©tricas Last.fm).\")\n",
    "\n",
    "    # 2. Preparar e insertar la tabla ALBUMES\n",
    "    df_albumes = df_consolidado[\n",
    "        [\n",
    "            'ID_Album',\n",
    "            'Nombre_Album',\n",
    "            'A√±o_Lanzamiento_Album',\n",
    "            'Artista'  # FK a ARTISTAS\n",
    "        ]\n",
    "    ].drop_duplicates(subset=['ID_Album']).dropna(subset=['ID_Album'])\n",
    "\n",
    "    df_albumes = df_albumes.replace({np.nan: None})\n",
    "\n",
    "    df_albumes.to_sql(\n",
    "        'ALBUMES',\n",
    "        engine,\n",
    "        if_exists='fail',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'ID_Album': VARCHAR(50),\n",
    "            'Nombre_Album': VARCHAR(255),\n",
    "            'A√±o_Lanzamiento_Album': Integer,\n",
    "            'Artista': VARCHAR(255),\n",
    "        },\n",
    "        chunksize=100\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"ALTER TABLE ALBUMES ADD PRIMARY KEY (ID_Album)\"))\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE ALBUMES \"\n",
    "                 \"ADD CONSTRAINT fk_albumes_artista \"\n",
    "                 \"FOREIGN KEY (Artista) REFERENCES ARTISTAS(Artista)\")\n",
    "        )\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"‚úÖ Insertados {len(df_albumes)} √°lbumes √∫nicos en la tabla ALBUMES.\")\n",
    "\n",
    "    # 3. Preparar e insertar la tabla CANCIONES (a√±adimos solo Popularidad)\n",
    "    df_canciones = df_consolidado[\n",
    "        [\n",
    "            'ID_Spotify',\n",
    "            'Nombre',\n",
    "            'A√±o_lanzamiento',\n",
    "            'ID_Album',\n",
    "            'Artista',\n",
    "            'genero_id',\n",
    "            'Popularidad'  # campo a√±adido\n",
    "        ]\n",
    "    ].drop_duplicates(subset=['ID_Spotify']).dropna(subset=['ID_Spotify'])\n",
    "\n",
    "    df_canciones = df_canciones.replace({np.nan: None})\n",
    "\n",
    "    df_canciones.to_sql(\n",
    "        'CANCIONES',\n",
    "        engine,\n",
    "        if_exists='fail',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'ID_Spotify': VARCHAR(50),\n",
    "            'Nombre': VARCHAR(255),\n",
    "            'A√±o_lanzamiento': Integer,\n",
    "            'ID_Album': VARCHAR(50),\n",
    "            'Artista': VARCHAR(255),\n",
    "            'genero_id': Integer,\n",
    "            'Popularidad': Integer\n",
    "        },\n",
    "        chunksize=100\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        # 3.1 Definir la PK\n",
    "        connection.execute(text(\"ALTER TABLE CANCIONES ADD PRIMARY KEY (ID_Spotify)\"))\n",
    "\n",
    "        # 3.2 A√±adir claves for√°neas (con nombres de constraint expl√≠citos)\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE CANCIONES \"\n",
    "                 \"ADD CONSTRAINT fk_canciones_album \"\n",
    "                 \"FOREIGN KEY (ID_Album) REFERENCES ALBUMES(ID_Album)\")\n",
    "        )\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE CANCIONES \"\n",
    "                 \"ADD CONSTRAINT fk_canciones_genero \"\n",
    "                 \"FOREIGN KEY (genero_id) REFERENCES GENEROS(genero_id)\")\n",
    "        )\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE CANCIONES \"\n",
    "                 \"ADD CONSTRAINT fk_canciones_artista \"\n",
    "                 \"FOREIGN KEY (Artista) REFERENCES ARTISTAS(Artista)\")\n",
    "        )\n",
    "\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"‚úÖ Insertadas {len(df_canciones)} canciones √∫nicas en la tabla CANCIONES (con Popularidad).\")\n",
    "\n",
    "    print(\"\\n--- FASE 2 (MODELADO) COMPLETADA. Datos normalizados insertados en MySQL. ---\")\n",
    "\n",
    "# --- CELDA DE VERIFICACI√ìN (A√ëADIMOS LA POPULARIDAD) ---\n",
    "try:\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        g.nombre_genero,\n",
    "        COUNT(c.ID_Spotify) AS Total_Canciones,\n",
    "        ROUND(AVG(c.Popularidad), 2) AS Avg_Popularidad\n",
    "    FROM\n",
    "        CANCIONES c\n",
    "    JOIN\n",
    "        GENEROS g ON c.genero_id = g.genero_id\n",
    "    GROUP BY\n",
    "        g.nombre_genero;\n",
    "    \"\"\"\n",
    "\n",
    "    df_verification = pd.read_sql(query, engine)\n",
    "\n",
    "    if df_verification.empty:\n",
    "        print(\"‚ö†Ô∏è Advertencia: La tabla 'CANCIONES' est√° vac√≠a o no se encontr√≥.\")\n",
    "    else:\n",
    "        print(\"\\n--- VERIFICACI√ìN DE G√âNEROS Y POPULARIDAD EN LA BASE DE DATOS ---\")\n",
    "        print(df_verification)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR al verificar la base de datos: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
