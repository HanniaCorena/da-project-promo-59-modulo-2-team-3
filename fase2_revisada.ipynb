{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f75e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base de datos 'musica_db' creada o verificada en el servidor.\n",
      "✅ Conexión establecida a la base de datos MySQL: musica_db\n",
      "\n",
      "--- ¡LISTO PARA LA CARGA DE DATOS Y MODELADO! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, BigInteger, Text, VARCHAR # <--- ¡ESTAS!\n",
    "from sqlalchemy.sql import text # <--- ¡ESTA!\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar las credenciales y definir el motor de conexión\n",
    "load_dotenv('2.env')\n",
    "\n",
    "CSV_FILENAME = 'reggaeton_data_2010_2024.csv' # Esto se usará solo si es necesario, pero la Celda 2 lo anula.\n",
    "DB_USER = os.getenv(\"MYSQL_USER\")\n",
    "DB_PASSWORD = os.getenv(\"MYSQL_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"MYSQL_HOST\")\n",
    "# Usaremos 'musica_db' directamente\n",
    "DB_DATABASE = \"musica_db\"\n",
    "\n",
    "engine = None # Inicializamos la variable\n",
    "\n",
    "try:\n",
    "    # --- PASO 1: CONECTARSE AL SERVIDOR Y CREAR LA BASE DE DATOS ---\n",
    "   \n",
    "    # 1.1 Conexión sin especificar la base de datos (Database=None)\n",
    "    conn_no_db = mysql.connector.connect(\n",
    "        host=DB_HOST,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    cursor = conn_no_db.cursor()\n",
    "   \n",
    "    # 1.2 Crear la base de datos si no existe\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {DB_DATABASE}\")\n",
    "    cursor.close()\n",
    "    conn_no_db.close()\n",
    "   \n",
    "    print(f\"✅ Base de datos '{DB_DATABASE}' creada o verificada en el servidor.\")\n",
    "   \n",
    "   \n",
    "    # --- PASO 2: CREAR EL ENGINE FINAL CON LA BASE DE DATOS ESPECIFICADA ---\n",
    "   \n",
    "    mysql_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_DATABASE}\"\n",
    "    engine = create_engine(mysql_url)\n",
    "   \n",
    "    print(f\"✅ Conexión establecida a la base de datos MySQL: {DB_DATABASE}\")\n",
    "\n",
    "    print(\"\\n--- ¡LISTO PARA LA CARGA DE DATOS Y MODELADO! ---\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"❌ ERROR: Asegúrate de que instalaste 'mysql-connector-python' o 'mysqlclient'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR CRÍTICO DE CONEXIÓN: Verifica que tu servidor MySQL esté encendido y tus credenciales en '2.env' sean correctas. Detalle: {e}\")\n",
    "    engine = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b1c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO CARGA Y CONCATENACIÓN DE GÉNEROS ---\n",
      "   -> Cargado reggaeton_data_2010_2024.csv (Reggaeton) con 500 filas.\n",
      "   -> Cargado latin_data_2010_2024.csv (Pop Latino) con 500 filas.\n",
      "   -> Cargado funk_data_2010_2024.csv (Funk) con 500 filas.\n",
      "   -> Cargado indie_data_2010_2024.csv (Rock Indie) con 500 filas.\n",
      "   -> Cargado data_jazz_final2.csv (jazz) con 500 filas.\n",
      "\n",
      "Total ÚNICO de canciones (Global): 2468\n"
     ]
    }
   ],
   "source": [
    "# --- CELDA 2: CARGA, CONSOLIDACIÓN Y MAPEO DE GÉNEROS ---\n",
    "\n",
    "# 1. Lista de archivos y sus géneros correspondientes (AJUSTA ESTA LISTA)\n",
    "file_info = [\n",
    "    {'name': 'reggaeton_data_2010_2024.csv', 'genre': 'Reggaeton'},\n",
    "    {'name': 'latin_data_2010_2024.csv', 'genre': 'Pop Latino'},\n",
    "    {'name': 'funk_data_2010_2024.csv', 'genre': 'Funk'},\n",
    "    {'name': 'indie_data_2010_2024.csv', 'genre': 'Rock Indie'},\n",
    "    {'name': 'data_jazz_final2.csv', 'genre': 'jazz'},\n",
    "    \n",
    "    # {'name': 'indie_rock_data.csv', 'genre': 'Indie Rock'},\n",
    "]\n",
    "\n",
    "all_dataframes = []\n",
    "print(\"--- INICIANDO CARGA Y CONCATENACIÓN DE GÉNEROS ---\")\n",
    "\n",
    "for info in file_info:\n",
    "    filename = info['name']\n",
    "    genre = info['genre']\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        df['Genero'] = genre\n",
    "       \n",
    "        # Opcional pero Recomendado: Renombrar para consistencia\n",
    "        if 'Año de lanzamiento' in df.columns:\n",
    "            df.rename(columns={'Año de lanzamiento': 'Año_lanzamiento'}, inplace=True)\n",
    "\n",
    "        all_dataframes.append(df)\n",
    "        print(f\"   -> Cargado {filename} ({genre}) con {len(df)} filas.\")\n",
    "       \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ ERROR: Archivo NO encontrado: {filename}. ¡Asegúrate de que el nombre es EXACTO!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error al leer {filename}: {e}\")\n",
    "\n",
    "df_consolidado = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# 2. Deduplicación Final (vital para análisis multi-género)\n",
    "initial_rows = len(df_consolidado)\n",
    "df_consolidado.drop_duplicates(subset=['ID_Spotify'], keep='first', inplace=True)\n",
    "final_rows = len(df_consolidado)\n",
    "print(f\"\\nTotal ÚNICO de canciones (Global): {final_rows}\")\n",
    "\n",
    "# --- PREPARACIÓN DE LA TABLA GENEROS Y MAPEO ---\n",
    "# 3. Extraer géneros únicos\n",
    "df_generos_map = df_consolidado[['Genero']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 4. Asignar un ID temporal para la inserción (IMPORTANTE: MySQL le asignará el ID final)\n",
    "# Esto asegura que tengamos el mismo orden en el DataFrame y en la BD.\n",
    "df_generos_map['genero_id'] = df_generos_map.index + 1\n",
    "\n",
    "# 5. Fusionar (Merge) el ID del género de vuelta al DataFrame consolidado\n",
    "df_consolidado = pd.merge(\n",
    "    df_consolidado,\n",
    "    df_generos_map[['Genero', 'genero_id']],\n",
    "    on='Genero',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Creamos el DataFrame final para insertar en la tabla GENEROS\n",
    "df_generos_db = df_generos_map[['genero_id', 'Genero']].rename(columns={'Genero': 'nombre_genero'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb20b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO INSERCIÓN DE DATOS CONSOLIDADOS EN MYSQL ---\n",
      "✅ Insertados 5 géneros únicos en la tabla GENEROS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_19460\\1988075318.py:23: UserWarning: The provided table name 'GENEROS' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_generos_db.to_sql(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_19460\\1988075318.py:58: UserWarning: The provided table name 'ARTISTAS' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_artistas.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Insertados 1251 artistas únicos en la tabla ARTISTAS (con métricas Last.fm).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_19460\\1988075318.py:89: UserWarning: The provided table name 'ALBUMES' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_albumes.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Insertados 1490 álbumes únicos en la tabla ALBUMES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_19460\\1988075318.py:129: UserWarning: The provided table name 'CANCIONES' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_canciones.to_sql(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Insertadas 2468 canciones únicas en la tabla CANCIONES (con Popularidad).\n",
      "\n",
      "--- FASE 2 (MODELADO) COMPLETADA. Datos normalizados insertados en MySQL. ---\n",
      "\n",
      "--- VERIFICACIÓN DE GÉNEROS Y POPULARIDAD EN LA BASE DE DATOS ---\n",
      "  nombre_genero  Total_Canciones  Avg_Popularidad\n",
      "0          jazz              496              NaN\n",
      "1          Funk              499            18.33\n",
      "2    Pop Latino              490            40.54\n",
      "3    Rock Indie              483            38.14\n",
      "4     Reggaeton              500            45.30\n"
     ]
    }
   ],
   "source": [
    "# --- CELDA 3: INSERCIÓN DE DATOS CON NORMALIZACIÓN EN MYSQL (CORREGIDA: SOLO AÑADIDA POPULARIDAD) ---\n",
    "\n",
    "# Asegúrate de que las librerías necesarias estén importadas al inicio del notebook.\n",
    "# from sqlalchemy.types import Integer, BigInteger, Text, VARCHAR \n",
    "# from sqlalchemy.sql import text\n",
    "\n",
    "if 'engine' not in locals() or engine is None:\n",
    "    print(\"❌ ERROR: El motor de conexión a MySQL no se creó correctamente.\")\n",
    "elif 'df_consolidado' not in locals():\n",
    "    print(\"❌ ERROR: El DataFrame consolidado no se encontró. ¡Ejecuta la Celda 2 (Consolidación) primero!\")\n",
    "else:\n",
    "    print(\"--- INICIANDO INSERCIÓN DE DATOS CONSOLIDADOS EN MYSQL ---\")\n",
    "\n",
    "    # Limpieza previa de tablas para evitar problemas con to_sql/replace y claves\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS CANCIONES\"))\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS ALBUMES\"))\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS ARTISTAS\"))\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS GENEROS\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # 0. Crear e insertar la tabla GENEROS\n",
    "    df_generos_db.to_sql(\n",
    "        'GENEROS',\n",
    "        engine,\n",
    "        if_exists='fail',   # ya hemos hecho DROP antes\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'genero_id': Integer,\n",
    "            'nombre_genero': VARCHAR(50)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(\n",
    "            text(\n",
    "                \"ALTER TABLE GENEROS \"\n",
    "                \"MODIFY genero_id INT NOT NULL AUTO_INCREMENT, \"\n",
    "                \"ADD PRIMARY KEY (genero_id)\"\n",
    "            )\n",
    "        )\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"✅ Insertados {len(df_generos_db)} géneros únicos en la tabla GENEROS.\")\n",
    "\n",
    "    # 1. Preparar e insertar la tabla ARTISTAS (con datos de Last.fm)\n",
    "    df_artistas = df_consolidado[\n",
    "        [\n",
    "            'Artista',\n",
    "            'Playcount_LastFM',\n",
    "            'Listeners_LastFM',\n",
    "            'Biografia_Resumen'\n",
    "        ]\n",
    "    ].drop_duplicates(subset=['Artista']).dropna(subset=['Artista'])\n",
    "\n",
    "    df_artistas = df_artistas.replace({np.nan: None})\n",
    "\n",
    "    df_artistas.to_sql(\n",
    "        'ARTISTAS',\n",
    "        engine,\n",
    "        if_exists='fail',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'Artista': VARCHAR(255),\n",
    "            'Playcount_LastFM': BigInteger,\n",
    "            'Listeners_LastFM': BigInteger,\n",
    "            'Biografia_Resumen': Text\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"ALTER TABLE ARTISTAS ADD PRIMARY KEY (Artista)\"))\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"✅ Insertados {len(df_artistas)} artistas únicos en la tabla ARTISTAS (con métricas Last.fm).\")\n",
    "\n",
    "    # 2. Preparar e insertar la tabla ALBUMES\n",
    "    df_albumes = df_consolidado[\n",
    "        [\n",
    "            'ID_Album',\n",
    "            'Nombre_Album',\n",
    "            'Año_Lanzamiento_Album',\n",
    "            'Artista'  # FK a ARTISTAS\n",
    "        ]\n",
    "    ].drop_duplicates(subset=['ID_Album']).dropna(subset=['ID_Album'])\n",
    "\n",
    "    df_albumes = df_albumes.replace({np.nan: None})\n",
    "\n",
    "    df_albumes.to_sql(\n",
    "        'ALBUMES',\n",
    "        engine,\n",
    "        if_exists='fail',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'ID_Album': VARCHAR(50),\n",
    "            'Nombre_Album': VARCHAR(255),\n",
    "            'Año_Lanzamiento_Album': Integer,\n",
    "            'Artista': VARCHAR(255),\n",
    "        },\n",
    "        chunksize=100\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"ALTER TABLE ALBUMES ADD PRIMARY KEY (ID_Album)\"))\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE ALBUMES \"\n",
    "                 \"ADD CONSTRAINT fk_albumes_artista \"\n",
    "                 \"FOREIGN KEY (Artista) REFERENCES ARTISTAS(Artista)\")\n",
    "        )\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"✅ Insertados {len(df_albumes)} álbumes únicos en la tabla ALBUMES.\")\n",
    "\n",
    "    # 3. Preparar e insertar la tabla CANCIONES (añadimos solo Popularidad)\n",
    "    df_canciones = df_consolidado[\n",
    "        [\n",
    "            'ID_Spotify',\n",
    "            'Nombre',\n",
    "            'Año_lanzamiento',\n",
    "            'ID_Album',\n",
    "            'Artista',\n",
    "            'genero_id',\n",
    "            'Popularidad'  # campo añadido\n",
    "        ]\n",
    "    ].drop_duplicates(subset=['ID_Spotify']).dropna(subset=['ID_Spotify'])\n",
    "\n",
    "    df_canciones = df_canciones.replace({np.nan: None})\n",
    "\n",
    "    df_canciones.to_sql(\n",
    "        'CANCIONES',\n",
    "        engine,\n",
    "        if_exists='fail',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'ID_Spotify': VARCHAR(50),\n",
    "            'Nombre': VARCHAR(255),\n",
    "            'Año_lanzamiento': Integer,\n",
    "            'ID_Album': VARCHAR(50),\n",
    "            'Artista': VARCHAR(255),\n",
    "            'genero_id': Integer,\n",
    "            'Popularidad': Integer\n",
    "        },\n",
    "        chunksize=100\n",
    "    )\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        # 3.1 Definir la PK\n",
    "        connection.execute(text(\"ALTER TABLE CANCIONES ADD PRIMARY KEY (ID_Spotify)\"))\n",
    "\n",
    "        # 3.2 Añadir claves foráneas (con nombres de constraint explícitos)\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE CANCIONES \"\n",
    "                 \"ADD CONSTRAINT fk_canciones_album \"\n",
    "                 \"FOREIGN KEY (ID_Album) REFERENCES ALBUMES(ID_Album)\")\n",
    "        )\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE CANCIONES \"\n",
    "                 \"ADD CONSTRAINT fk_canciones_genero \"\n",
    "                 \"FOREIGN KEY (genero_id) REFERENCES GENEROS(genero_id)\")\n",
    "        )\n",
    "        connection.execute(\n",
    "            text(\"ALTER TABLE CANCIONES \"\n",
    "                 \"ADD CONSTRAINT fk_canciones_artista \"\n",
    "                 \"FOREIGN KEY (Artista) REFERENCES ARTISTAS(Artista)\")\n",
    "        )\n",
    "\n",
    "        connection.commit()\n",
    "\n",
    "    print(f\"✅ Insertadas {len(df_canciones)} canciones únicas en la tabla CANCIONES (con Popularidad).\")\n",
    "\n",
    "    print(\"\\n--- FASE 2 (MODELADO) COMPLETADA. Datos normalizados insertados en MySQL. ---\")\n",
    "\n",
    "# --- CELDA DE VERIFICACIÓN (AÑADIMOS LA POPULARIDAD) ---\n",
    "try:\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        g.nombre_genero,\n",
    "        COUNT(c.ID_Spotify) AS Total_Canciones,\n",
    "        ROUND(AVG(c.Popularidad), 2) AS Avg_Popularidad\n",
    "    FROM\n",
    "        CANCIONES c\n",
    "    JOIN\n",
    "        GENEROS g ON c.genero_id = g.genero_id\n",
    "    GROUP BY\n",
    "        g.nombre_genero;\n",
    "    \"\"\"\n",
    "\n",
    "    df_verification = pd.read_sql(query, engine)\n",
    "\n",
    "    if df_verification.empty:\n",
    "        print(\"⚠️ Advertencia: La tabla 'CANCIONES' está vacía o no se encontró.\")\n",
    "    else:\n",
    "        print(\"\\n--- VERIFICACIÓN DE GÉNEROS Y POPULARIDAD EN LA BASE DE DATOS ---\")\n",
    "        print(df_verification)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR al verificar la base de datos: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter)",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
